{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "hcXFtCPkDqoxd6Hwrjx1ME",
     "type": "MD"
    }
   },
   "source": [
    "# **This is the collaborative code for the group project QTEM Data Challenge**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "RBcxvzmNL2UKbfeFkW7aV7",
     "type": "MD"
    }
   },
   "source": [
    "###  Before editing or contributing to this code, you should create a side notebook where you can test your ideas\n",
    "You can do so by cloning this notebook under another name\n",
    "\n",
    "Also, when adding a cell, make sure you comment and put a title on what you are doing so we can keep track of all steps\n",
    "\n",
    "Have FUN!!!\n",
    "\n",
    "## Markdowns: \n",
    "\n",
    "### You can change the cell type to Markdown in the dropdown list in the top menu\n",
    "### Add a cell, then select Mardown\n",
    "### You can then write text under different format\n",
    "### Use the \"#\" symbol before your text to make it bigger\n",
    "# \"#\" will make it Super large\n",
    "## \"##\" a bit smaller\n",
    "### \"###\" a bit smaller\n",
    "##### \"####\" you get the point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ____ __________________ _________ _______ __________ ______________ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "Hy5AE4C3yU1sHWUkVI4sTk",
     "type": "MD"
    }
   },
   "source": [
    "## 1. Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "l0VMpiYvVHyQGAl5HB81ey",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "vxjFia3zrHzPmN8t1uzcnR",
     "type": "MD"
    }
   },
   "source": [
    "## 2. Importing data and defining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important information / clarification about the datasets: \n",
    "\n",
    "SENT BY MAIO VITTORIO THROUGH FORUM: \n",
    "\n",
    "\"\"Cartier Data Science expert would like to make a clarification on the transactions in the dataset: in the dataset there are not only repurchasing clients coming back after more than 4 years, But also clients repurchasing clients coming back before this threshold.\n",
    "\n",
    "In terms of the project requirement, this does not impact what is expected from you. The statistics about repurchasing customers after 4 years is something that Cartier started to investigate and which would be the best starting point for your research. Of course, if it is possible to also investigate other types of returning customers, it could add a different perspective (and possibly a better insight) of repurchasing customers’ behaviour.\"\" \n",
    "\n",
    "### This means we could / should also analyze the data from customers who return after less than 4 years\n",
    "### I think we should start by the ones coming after 4 years since this is the central point \n",
    "### We could deep further if we deem it necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "nyn7xcYNXoOQngwGrnjdPo",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "df_Calls = pd.read_csv(\"b. CARTIER_CALLS.csv\")\n",
    "df_Clienteling = pd.read_csv(\"c. CARTIER_CLIENTELING.csv\")\n",
    "df_Livechat = pd.read_csv(\"d. CARTIER_LIVECHAT.csv\")\n",
    "df_PrevSales = pd.read_csv(\"e. CARTIER_PREVIOUS_SALES.csv\")\n",
    "df_Sales = pd.read_csv(\"f. CARTIER_SALES.csv\")\n",
    "df_Wishlist = pd.read_csv(\"g. CARTIER_WISHLIST.csv\")\n",
    "\n",
    "# Merged sales and previous sales dataset with extra column [in_salesdataset] to indicate to which original dataset \n",
    "# the data belong\n",
    "\n",
    "df_Sales['in_salesdataset']=1\n",
    "df_PrevSales['in_salesdataset']=0\n",
    "df_AllSales = pd.concat([df_Sales, df_PrevSales])\n",
    "df_AllSales = df_AllSales.sort_values(by='ClientID', ascending= True)\n",
    "\n",
    "#to export a dataframe to excel (for siqi): \n",
    "\n",
    "#df_BLABLABLA.to_csv('df_BLABLABLA.csv')\n",
    "\n",
    "# Define a sample dataset to work with for speed purposes if necessary (10% of size)\n",
    "\n",
    "#df_AllSalesSample = df_AllSales.head(int(round((len(df_allsales)/(10)),0)))\n",
    "# How to get a random sample of the dataset ??\n",
    "## df_Prevsales=df_Prevsales.sample(frac=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "dUPRadFx3IO8tnqSVXv2MQ",
     "type": "MD"
    }
   },
   "source": [
    "## 3. Quick look at our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "I6Ly9SvBZdU7pyUvUZWWh9",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['InvoiceHeader', 'Channel', 'TransactionDate', 'TransactionDate_FYYYY', 'TransactionCategory', 'ClientID', 'AgeAtTransaction', 'Gender', 'PersonBirthDate', 'WeddingDate', 'SpokenLanguage', 'WrittenLanguage', 'FirstSalesDate', 'FirstTransactionDate', 'ProductCategory', 'ProductSubCategory', 'ProductFunction', 'Turnover', 'quantity', 'seq_sales_trs', 'nb_days_since_last_sale', 'PurchasedMarketA', 'PurchasedRegionA', 'ResidencyRegionA', 'ResidencyMarketA', 'BoutiqueNameA', 'ResidencyCountryA', 'nationalityA', 'articleA', 'Hier_Lev_3_txtA', 'Hier_Lev_4_txtA', 'Hier_Lev_5_txtA', 'ProductCollectionA', 'in_salesdataset', 'NationalityA', 'ArticleA']\n"
     ]
    }
   ],
   "source": [
    "# To see the columns we have \n",
    "\n",
    "# Run this line if you wish to be able to visualize all the columns whenever you print out the dataframe\n",
    "\n",
    "#pd.set_option('max_columns', None)\n",
    "\n",
    "print(list(df_AllSales))\n",
    "#print(list(anything else you want to see))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "MRlVkGJQ5qogO55sBV5NCR",
     "type": "MD"
    }
   },
   "source": [
    "## 4. Generating the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "7EUPdfz7NnQkQo0TdeDHZ8",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "### We can generate a profile to obtain description of our datasets\n",
    "### This can take some time if running report on large datasets\n",
    "### We can run the report on our sample dataset\n",
    "\n",
    "# Profile for Sales Sample\n",
    "\n",
    "#Profile_AllSalesSample = ProfileReport(df_Allsales, title=\"Pandas Profiling Report Sales\")\n",
    "\n",
    "# Visualizing the report\n",
    "\n",
    "#Report to iframe (will open report in notebook)\n",
    "\n",
    "#Profile_AllSalesSample.to_notebook_iframe()\n",
    "\n",
    "## Report to HTML (Will open up a new tab)\n",
    "#Profile_AllSalesSample.to_file(output_file='All Sales Sample report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next we would like to create new columns in [Allsales] to identify wether clientID is present in [Calls], [LiveChat], [Clienteling] or any one of the 3 (we can call this column: \"interaction' and assign 1 if there was interaction of any kind and 0 otherwise.\n",
    "\n",
    "### This will be needed to filter our data and run a multidimentional analysis\n",
    "#### To answer questions regarding contacts and communication between Cartier and Clients, we only need data concerning ClientsID who've had interactions with Cartier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are \n",
      "\n",
      "    ClientID  blabla\n",
      "0         1       2\n",
      "1         2       3\n",
      "2         3       4 \n",
      "    ClientID  dateofcall\n",
      "0         2           2\n",
      "1         3           3\n",
      "2         4           4 \n",
      "    ClientID  blabla  Interaction?\n",
      "0         1       2             0\n",
      "1         2       3             1\n",
      "2         3       4             1\n"
     ]
    }
   ],
   "source": [
    "#Code:\n",
    "\n",
    "# Example of what we want\n",
    "ExampleSales1 = {'ClientID': [1,2,3], 'blabla': [2,3,4]}\n",
    "df_ExampleSales1 = pd.DataFrame(ExampleSales1)\n",
    "\n",
    "ExampleCall1= {'ClientID':[2,3,4], 'dateofcall':[2,3,4]}\n",
    "df_ExampleCall1 = pd.DataFrame(ExampleCall1)\n",
    "df_finaldataset = pd.DataFrame()\n",
    "df_finaldataset = df_finaldataset.append(df_ExampleSales1)\n",
    "df_finaldataset['Interaction?'] = [0,1,1]\n",
    "\n",
    "# Result: \n",
    "print(\"Results are \\n\\n\", df_ExampleSales1,\"\\n\", df_ExampleCall1, \"\\n\", df_finaldataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generate a table which shows what % of total # of ClientID are present in Calls, Livechat, Clienteling and all 3 of them. \n",
    "## Not so useful... As we have this information through excel already, but it can be a good coding exercise :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ## We could filter [AllSales] in order to obtain only the clientID which repurchased after 4 years. This could allow us to look into details what's special about those clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClientID                   126048\n",
       "nb_days_since_last_sale    126048\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code \n",
    "#1. Create a new dataframe that is sorted by nb_days_since_last_sale, descending\n",
    "#df_sortedallsalesbydays = df_AllSales.sort_values(\"nb_days_since_last_sale\" , axis=0, ascending=False)\n",
    "\n",
    "#2. Visusalize the top 2 records \n",
    "#print(sortedallsalesbydays[[\"ClientID\", \"nb_days_since_last_sale\"]].head(2))\n",
    "\n",
    "#3. Here we count the number of clients with last sale since more than 1460 days (about 4 years)\n",
    "\n",
    "#df_sortedallsalesbydays[df_sortedallsalesbydays.nb_days_since_last_sale > 1460].filter([\"ClientID\", \"nb_days_since_last_sale\"]).count(axis=0)\n",
    "\n",
    "# Answer: There are 126048 record in our dataset with their last purchase made 4 years ago or more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Filter [AllSales] by Interaction = 1\n",
    "\n",
    "## What kind of question can we answer with this data? (Brainstorm needed)\n",
    "### Were the purchases made right after communication? \n",
    "#### Compare date of purchase with date of latest interaction\n",
    "### Which type of communication caused the most repurchases ? \n",
    "#### Can we use turnover to evaluate which type of communication made the most revenues?\n",
    "\n",
    " \n",
    "## Clienteling:\n",
    "### What kind of activity category is most effective\n",
    "### Make a ranking by activity category and type\n",
    "### Any link between activity status and repurchase / sale amount? \n",
    "\n",
    "## Wishlist:\n",
    "### Do clients with a wishlist repurchase after 4 years? \n",
    "### Any link between last modified date, created date and purchase date?\n",
    "\n",
    "## All Sales\n",
    "### Make a ranking of product categories repurchased after 4 years in order of magnitude\n",
    "### Make another table with a column to identify if product repurchased is in same category, subcategory,  of first product bought\n",
    "### Whats up with wedding dates / anniversary dates and repurchase?\n",
    "\n",
    "## Calls\n",
    "\n",
    "\n",
    "## Livechat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Yann Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset as much as possible \n",
    "# Then run premilimary anaysis / desc statistics\n",
    "# Recode variables \n",
    "# Logistic regression : \n",
    "# y : Client rebought after 4 years or no\n",
    "\n",
    "# y: look at y=1\n",
    "# try to do some clustering according to key variables (product_category?, wedding?, anniversary?, INTERACTION???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Regarding yann's recommendations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ClientID  number_of_days_since_last_sale\n",
      "0         1                              10\n",
      "1         1                              20\n",
      "2         2                              10\n",
      "3         3                              10 \n",
      "\n",
      " As you can see, ClientID 1 appears twice but we want to 'Summarize' it\n"
     ]
    }
   ],
   "source": [
    "# When he says \"reduce dataset as much as possible\",\n",
    "# he means we have to make sure that we have unique values for ClientID\n",
    "# Since Clients appear more than once due to the fact that some of them have purchased more than once,\n",
    "# We must find a way to \"summarize\" every client in a way that we end up with only unique ClientIDs in the ClientID column\n",
    "\n",
    "# For example: \n",
    "\n",
    "\n",
    "examplereduce = {\n",
    "    \"ClientID\": [1,1,2,3],\n",
    "    \"number_of_days_since_last_sale\": [10,20,10,10]}\n",
    "\n",
    "df_examplereduce = pd.DataFrame(examplereduce)\n",
    "\n",
    "print(df_examplereduce, \"\\n\\n\", \"As you can see, ClientID 1 appears twice but we want to 'Summarize' it\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          number_of_days_since_last_sale\n",
      "ClientID                                \n",
      "1                                     15\n",
      "2                                     10\n",
      "3                                     10\n",
      " \n",
      " As you can see, we now only have one record for each ClientID, grouped by the mean of number_of_days_since_last_sale\n"
     ]
    }
   ],
   "source": [
    "# We can summarize it by using the groupby function from panda\n",
    "\n",
    "df_examplegroupedby = df_examplereduce.groupby(['ClientID']).mean()\n",
    "\n",
    "print(df_examplegroupedby)\n",
    "\n",
    "# Here we specify that we want to group ClientID by their mean\n",
    "\n",
    "print(\" \\n As you can see, we now only have one record for each ClientID, grouped by the mean of number_of_days_since_last_sale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is easy and pretty straightforward because only the \"number_of_days_since_last_sale\" was summarized\n",
    "## We have to figure out how we want each column to be summarized for each ClientID \n",
    "## Amber and Riccardo: If you could look at each variables from the All_sales dataset and figure out if\n",
    "### 1. We can actually group the variable (for example: some variables can't be grouped, or it is difficult to group them)\n",
    "###   Categorical variables are tricky: (If we look at product_category: \n",
    "###   how do you summarize if someone bought a watch and a necklage?, you cant do average on a categorical variable\n",
    "### However, you can group by the mode, meaning the product_category that appeared the most\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceHeader</th>\n",
       "      <th>Channel</th>\n",
       "      <th>TransactionDate</th>\n",
       "      <th>TransactionDate_FYYYY</th>\n",
       "      <th>TransactionCategory</th>\n",
       "      <th>ClientID</th>\n",
       "      <th>AgeAtTransaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PersonBirthDate</th>\n",
       "      <th>WeddingDate</th>\n",
       "      <th>SpokenLanguage</th>\n",
       "      <th>WrittenLanguage</th>\n",
       "      <th>FirstSalesDate</th>\n",
       "      <th>FirstTransactionDate</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ProductSubCategory</th>\n",
       "      <th>ProductFunction</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>quantity</th>\n",
       "      <th>seq_sales_trs</th>\n",
       "      <th>nb_days_since_last_sale</th>\n",
       "      <th>PurchasedMarketA</th>\n",
       "      <th>PurchasedRegionA</th>\n",
       "      <th>ResidencyRegionA</th>\n",
       "      <th>ResidencyMarketA</th>\n",
       "      <th>BoutiqueNameA</th>\n",
       "      <th>ResidencyCountryA</th>\n",
       "      <th>nationalityA</th>\n",
       "      <th>articleA</th>\n",
       "      <th>Hier_Lev_3_txtA</th>\n",
       "      <th>Hier_Lev_4_txtA</th>\n",
       "      <th>Hier_Lev_5_txtA</th>\n",
       "      <th>ProductCollectionA</th>\n",
       "      <th>in_salesdataset</th>\n",
       "      <th>NationalityA</th>\n",
       "      <th>ArticleA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122626</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Boutique</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sale</td>\n",
       "      <td>0011i00000UNT9LAAX</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1964-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.678613</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2441.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134321</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Boutique</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sale</td>\n",
       "      <td>0011i00000UNT9LAAX</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1964-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.143832</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2441.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9874</th>\n",
       "      <td>000000010730476-GEMINI-/BIC/AZRIRBARP00</td>\n",
       "      <td>Boutique</td>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>2012</td>\n",
       "      <td>Repair</td>\n",
       "      <td>0011i00000UNT9LAAX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1964-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>WATCHES</td>\n",
       "      <td>NON PRECIOUS W.</td>\n",
       "      <td>STEEL W.</td>\n",
       "      <td>447.008100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>635863.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Boutique</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2020</td>\n",
       "      <td>Sale</td>\n",
       "      <td>0011i00000UNT9LAAX</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1964-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>479.618832</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2441.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22358</th>\n",
       "      <td>302109220925007-GEMINI-/BIC/AZRIRBARP00</td>\n",
       "      <td>Boutique</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>2023</td>\n",
       "      <td>Sale</td>\n",
       "      <td>0011i00000UNT9LAAX</td>\n",
       "      <td>59.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1964-10-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2011-06-11</td>\n",
       "      <td>WATCHES</td>\n",
       "      <td>NON PRECIOUS W.</td>\n",
       "      <td>STEEL W.</td>\n",
       "      <td>8205.120000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>635779.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  InvoiceHeader   Channel TransactionDate  \\\n",
       "122626                                      NaN  Boutique      2019-12-14   \n",
       "134321                                      NaN  Boutique      2019-12-14   \n",
       "9874    000000010730476-GEMINI-/BIC/AZRIRBARP00  Boutique      2011-06-11   \n",
       "125277                                      NaN  Boutique      2019-12-14   \n",
       "22358   302109220925007-GEMINI-/BIC/AZRIRBARP00  Boutique      2022-09-25   \n",
       "\n",
       "        TransactionDate_FYYYY TransactionCategory            ClientID  \\\n",
       "122626                   2020                Sale  0011i00000UNT9LAAX   \n",
       "134321                   2020                Sale  0011i00000UNT9LAAX   \n",
       "9874                     2012              Repair  0011i00000UNT9LAAX   \n",
       "125277                   2020                Sale  0011i00000UNT9LAAX   \n",
       "22358                    2023                Sale  0011i00000UNT9LAAX   \n",
       "\n",
       "        AgeAtTransaction Gender PersonBirthDate WeddingDate SpokenLanguage  \\\n",
       "122626              56.0   Male      1964-10-13         NaN        English   \n",
       "134321              56.0   Male      1964-10-13         NaN        English   \n",
       "9874                48.0   Male      1964-10-13         NaN        English   \n",
       "125277              56.0   Male      1964-10-13         NaN        English   \n",
       "22358               59.0   Male      1964-10-13         NaN        English   \n",
       "\n",
       "       WrittenLanguage FirstSalesDate FirstTransactionDate ProductCategory  \\\n",
       "122626         English     2019-12-14           2011-06-11             NaN   \n",
       "134321         English     2019-12-14           2011-06-11             NaN   \n",
       "9874           English     2019-12-14           2011-06-11         WATCHES   \n",
       "125277         English     2019-12-14           2011-06-11             NaN   \n",
       "22358          English     2019-12-14           2011-06-11         WATCHES   \n",
       "\n",
       "       ProductSubCategory ProductFunction     Turnover  quantity  \\\n",
       "122626                NaN             NaN    65.678613         1   \n",
       "134321                NaN             NaN    81.143832         1   \n",
       "9874      NON PRECIOUS W.        STEEL W.   447.008100         1   \n",
       "125277                NaN             NaN   479.618832         1   \n",
       "22358     NON PRECIOUS W.        STEEL W.  8205.120000         1   \n",
       "\n",
       "        seq_sales_trs  nb_days_since_last_sale  PurchasedMarketA  \\\n",
       "122626              3                   2441.0                12   \n",
       "134321              3                   2441.0                12   \n",
       "9874                1                      NaN                 2   \n",
       "125277              3                   2441.0                12   \n",
       "22358               4                   1016.0                 2   \n",
       "\n",
       "        PurchasedRegionA  ResidencyRegionA  ResidencyMarketA  BoutiqueNameA  \\\n",
       "122626                 5                 5                12            NaN   \n",
       "134321                 5                 5                12            NaN   \n",
       "9874                   2                 5                12           88.0   \n",
       "125277                 5                 5                12            NaN   \n",
       "22358                  2                 5                12           89.0   \n",
       "\n",
       "        ResidencyCountryA  nationalityA  articleA  Hier_Lev_3_txtA  \\\n",
       "122626               89.0           NaN       NaN              NaN   \n",
       "134321               89.0           NaN       NaN              NaN   \n",
       "9874                 89.0           NaN       NaN             96.0   \n",
       "125277               89.0           NaN       NaN              NaN   \n",
       "22358                89.0          90.0  635779.0             96.0   \n",
       "\n",
       "        Hier_Lev_4_txtA  Hier_Lev_5_txtA  ProductCollectionA  in_salesdataset  \\\n",
       "122626              NaN              NaN                 NaN                0   \n",
       "134321              NaN              NaN                 NaN                0   \n",
       "9874              337.0            919.0                97.0                0   \n",
       "125277              NaN              NaN                 NaN                0   \n",
       "22358             336.0            722.0                83.0                1   \n",
       "\n",
       "        NationalityA  ArticleA  \n",
       "122626          90.0       NaN  \n",
       "134321          90.0       NaN  \n",
       "9874            90.0  635863.0  \n",
       "125277          90.0       NaN  \n",
       "22358            NaN       NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see all our columns\n",
    "\n",
    "df_AllSales.head()\n",
    "\n",
    "# There is a default limit of columns that panda will display, If you wish to be able to see all of them: \n",
    "#pd.set_option('max_columns', None)\n",
    "# then df_AllSales.head() again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'WATCHES' 'ACCESSORIES' 'JEWELRY'\n",
      " 'REFILL, CS ACCESSORIES OR SPARE PARTS' 'SERVICE' 'OTHER' 'GIFT'\n",
      " 'PACKAGING OR POS'] \n",
      "\n",
      " [nan 'NON PRECIOUS W.' 'FRAGRANCES' 'BIJOUX' 'OBJECTS' 'EYEWEAR'\n",
      " 'REFILL, SPARE PARTS OR CS ACCESSORIES (EXC STRAPS)' 'LG'\n",
      " 'LEATHER STRAPS' 'PRECIOUS W.' 'OTHER' 'HE W.' 'NJ' 'FJ' 'HJ'\n",
      " 'SPECIAL SALES' 'OTHER HIGH END']\n"
     ]
    }
   ],
   "source": [
    "# Yann also said to recode the variables\n",
    "# That's something you guys could look into\n",
    "\n",
    "# For example: Look at Product Category & Subproduct:\n",
    "\n",
    "print(df_AllSales.ProductCategory.unique(), \"\\n\\n\", df_AllSales.ProductSubCategory.unique())\n",
    "\n",
    "# We should assign numerical values to them if we determine there is some sort of ranking between them\n",
    "# Otherwise, we have to create a new column for each of them with the value 1 or 0 \n",
    "# We need this to run the logistic regression\n",
    "# Find which one of them comes up the more often and then decide if we want to create a new variable called\n",
    "# \"WATCHES\" which would be [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Where we're heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"Cartier Data Science expert would like to make a clarification on the transactions in the dataset: in the dataset there are not only repurchasing clients coming back after more than 4 years, But also clients repurchasing clients coming back before this threshold. \n",
    "\n",
    "In terms of the project requirement, this does not impact what is expected from you. The statistics about repurchasing customers after 4 years is something that Cartier started to investigate and which would be the best starting point for your research. Of course, if it is possible to also investigate other types of returning customers, it could add a different perspective (and possibly a better insight) of repurchasing customers’ behaviour.\"\"\n",
    "\n",
    "\n",
    "## In the sales It is very useful that we also have clients who DIDNT repurchase after 4 years because we can now run a Logistic Regression which will be y = x1 + x2 + x3 + u, where y = [0,1] \n",
    "## y=0 would indicate Client didn't repurchase after 4 years \n",
    "## y=1 would indicate Client did repurchase after 4 years\n",
    "## Our covariates x1, x2, ..., xi could be things like \"Turnover\", \"Product_Category\", \"Interaction\" -> (those are variables we have to create using the communication datasets we have)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "pandas-profiling",
     "source": "PIP",
     "version": "3.2.0"
    }
   ],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
